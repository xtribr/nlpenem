# ğŸ“ sabia-7b-enem-finetuned

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PEFT](https://img.shields.io/badge/PEFT-0.18.0-green.svg)](https://github.com/huggingface/peft)

Modelo de linguagem fine-tuned do **SABIA-7B** especializado em questÃµes e contexto do **ENEM** (Exame Nacional do Ensino MÃ©dio).

## ğŸ“‹ Sobre o Projeto

Este repositÃ³rio contÃ©m um modelo de linguagem adaptado usando **LoRA (Low-Rank Adaptation)** para ser especializado em:
- âœ… ResoluÃ§Ã£o e anÃ¡lise de questÃµes do ENEM
- âœ… ExplicaÃ§Ãµes didÃ¡ticas sobre Teoria da Resposta ao Item (TRI)
- âœ… AnÃ¡lise de desempenho estudantil
- âœ… Suporte educacional para estudantes do Ensino MÃ©dio
- âœ… GeraÃ§Ã£o de conteÃºdo educacional contextualizado

Desenvolvido pela **XTRI** - Especialista em ENEM/TRI e anÃ¡lise de dados educacionais.

## ğŸš€ InÃ­cio RÃ¡pido

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/xtribr/nlpenem.git
cd nlpenem

# Instale as dependÃªncias
pip install -r requirements.txt
```

### Uso BÃ¡sico

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# Carregar modelo base e adapter
base_model = "sabia-7b"  # Ajuste para o caminho do modelo base
adapter_path = "./checkpoint-367"

tokenizer = AutoTokenizer.from_pretrained(base_model)
model = AutoModelForCausalLM.from_pretrained(
    base_model,
    torch_dtype=torch.float16,
    device_map="auto"
)
model = PeftModel.from_pretrained(model, adapter_path)

# Gerar resposta
prompt = "Explique o conceito de Teoria da Resposta ao Item (TRI) no contexto do ENEM:"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=256,
        temperature=0.7,
        do_sample=True
    )

response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

Para mais exemplos, consulte o arquivo [`example_usage.py`](example_usage.py).

## ğŸ“Š MÃ©tricas de Treinamento

### Resultados Finais
- **Loss Final**: 0.68
- **Token Accuracy**: 84.19%
- **Total de Steps**: 367
- **Epochs**: 1.0

### EvoluÃ§Ã£o do Treinamento

| Step | Loss | Accuracy |
|------|------|----------|
| 25   | 1.12 | 75.13%   |
| 50   | 0.68 | 84.34%   |
| 100  | 0.65 | 84.41%   |
| 200  | 0.65 | 84.36%   |
| 300  | 0.64 | 84.63%   |
| 367  | 0.68 | 84.19%   |

ğŸ“ˆ Para anÃ¡lise detalhada, consulte [`ANALISE_TREINAMENTO.md`](ANALISE_TREINAMENTO.md).

## ğŸ”§ ConfiguraÃ§Ã£o TÃ©cnica

### HiperparÃ¢metros LoRA
- **Rank (r)**: 32
- **Alpha (Î±)**: 16
- **Dropout**: 0.05
- **Target Modules**: q_proj, k_proj, v_proj, o_proj
- **Bias**: none

### Stack TecnolÃ³gico
- **PEFT**: 0.18.0
- **TRL**: 0.25.1
- **Transformers**: 4.57.3
- **PyTorch**: 2.9.1
- **Datasets**: 4.4.1

## ğŸ“ Estrutura do Projeto

```
nlpenem/
â”œâ”€â”€ README.md                 # Este arquivo
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â”œâ”€â”€ .gitignore               # Arquivos ignorados pelo Git
â”œâ”€â”€ example_usage.py         # Exemplos de uso do modelo
â”œâ”€â”€ ANALISE_TREINAMENTO.md   # AnÃ¡lise detalhada do treinamento
â”œâ”€â”€ adapter_config.json      # ConfiguraÃ§Ã£o do adapter LoRA
â”œâ”€â”€ adapter_model.safetensors # Modelo adapter (LoRA weights)
â””â”€â”€ checkpoint-*/            # Checkpoints do treinamento
    â”œâ”€â”€ checkpoint-100/
    â”œâ”€â”€ checkpoint-200/
    â”œâ”€â”€ checkpoint-300/
    â””â”€â”€ checkpoint-367/      # Checkpoint final
```

## ğŸ“¦ Checkpoints DisponÃ­veis

O projeto inclui 4 checkpoints salvos durante o treinamento:

- **checkpoint-100**: Step 100 (Loss: 0.65, Accuracy: 84.41%)
- **checkpoint-200**: Step 200 (Loss: 0.65, Accuracy: 84.36%)
- **checkpoint-300**: Step 300 (Loss: 0.64, Accuracy: 84.63%) â­ **Recomendado**
- **checkpoint-367**: Step 367 (Loss: 0.68, Accuracy: 84.19%) - Final

ğŸ’¡ **RecomendaÃ§Ã£o**: O checkpoint-300 apresenta a melhor combinaÃ§Ã£o de mÃ©tricas (menor loss e maior accuracy).

## ğŸ¯ Casos de Uso

### 1. ResoluÃ§Ã£o de QuestÃµes ENEM
```python
questao = """
QuestÃ£o ENEM: Sobre a Teoria da Resposta ao Item (TRI), assinale a alternativa correta:
A) A TRI nÃ£o considera o nÃ­vel de dificuldade dos itens
B) A TRI permite comparar provas de diferentes ediÃ§Ãµes
...
"""
# Gerar resposta e explicaÃ§Ã£o
```

### 2. AnÃ¡lise de Desempenho
```python
notas = {
    "CH": 650.00,
    "CN": 620.00,
    "LC": 680.00,
    "MT": 700.00,
    "RedaÃ§Ã£o": 900.00
}
# Analisar e fornecer orientaÃ§Ãµes
```

### 3. ExplicaÃ§Ãµes DidÃ¡ticas
```python
# Explicar conceitos educacionais de forma didÃ¡tica
prompt = "Explique a diferenÃ§a entre nota TRI e nota bruta no ENEM:"
```

## âš ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes

- Este modelo foi fine-tuned para contexto educacional brasileiro e ENEM
- Os resultados devem ser validados por especialistas em educaÃ§Ã£o
- NÃ£o substitui estudo tradicional e orientaÃ§Ã£o pedagÃ³gica profissional
- Pode conter vieses presentes no dataset de treinamento
- Requer modelo base SABIA-7B para funcionar

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [Apache License 2.0](https://opensource.org/licenses/Apache-2.0).

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“š ReferÃªncias e CitaÃ§Ãµes

### TRL (Transformer Reinforcement Learning)
```bibtex
@misc{vonwerra2022trl,
    title        = {{TRL: Transformer Reinforcement Learning}},
    author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\'e}dec},
    year         = 2020,
    journal      = {GitHub repository},
    publisher    = {GitHub},
    howpublished = {\url{https://github.com/huggingface/trl}}
}
```

### LoRA (Low-Rank Adaptation)
```bibtex
@misc{hu2021lora,
    title={LoRA: Low-Rank Adaptation of Large Language Models},
    author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
    year={2021},
    eprint={2106.09685},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```

### SABIA-7B
- Modelo base: [SABIA-7B no Hugging Face](https://huggingface.co/sabia-7b)

## ğŸ‘¥ Autores

- **XTRI** - Especialista em ENEM/TRI e anÃ¡lise de dados educacionais
  - Professor de Ensino MÃ©dio
  - CEO da EdTech XTRI (Natal/RN)
  - Trabalha com dados educacionais crÃ­ticos (190k+ registros)

## ğŸ“§ Contato

Para questÃµes, sugestÃµes ou colaboraÃ§Ãµes:
- **GitHub**: [@xtribr](https://github.com/xtribr)
- **RepositÃ³rio**: [nlpenem](https://github.com/xtribr/nlpenem)

## ğŸ™ Agradecimentos

- Equipe do Hugging Face pelos frameworks TRL e PEFT
- Desenvolvedores do modelo SABIA-7B
- Comunidade open source de NLP em portuguÃªs

---

â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela no repositÃ³rio!

**Nota**: Este modelo Ã© parte de um projeto educacional focado em anÃ¡lise de dados ENEM e orientaÃ§Ã£o estudantil. Desenvolvido com responsabilidade e compromisso com a educaÃ§Ã£o de qualidade.
