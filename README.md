# üéì sabia-7b-enem-finetuned

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PEFT](https://img.shields.io/badge/PEFT-0.18.0-green.svg)](https://github.com/huggingface/peft)

Modelo de linguagem fine-tuned do **SABIA-7B** especializado em quest√µes e contexto do **ENEM** (Exame Nacional do Ensino M√©dio).

## üìã Sobre o Projeto

Este reposit√≥rio cont√©m um modelo de linguagem adaptado usando **LoRA (Low-Rank Adaptation)** para ser especializado em:
- ‚úÖ Resolu√ß√£o e an√°lise de quest√µes do ENEM
- ‚úÖ Explica√ß√µes did√°ticas sobre Teoria da Resposta ao Item (TRI)
- ‚úÖ An√°lise de desempenho estudantil
- ‚úÖ Suporte educacional para estudantes do Ensino M√©dio
- ‚úÖ Gera√ß√£o de conte√∫do educacional contextualizado

Desenvolvido pela **XTRI** - Especialista em ENEM/TRI e an√°lise de dados educacionais.

## üöÄ In√≠cio R√°pido

### Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/xtribr/nlpenem.git
cd nlpenem

# Instale as depend√™ncias
pip install -r requirements.txt
```

### Configura√ß√£o da API (Recomendado)

O modelo usa a **API SABIA-3.1 da Maritaca** ao inv√©s do modelo base local. Configure sua chave de API:

```bash
# Linux/Mac
export MARITACA_API_KEY='sua-chave-aqui'

# Windows (PowerShell)
$env:MARITACA_API_KEY='sua-chave-aqui'

# Ou crie um arquivo .env
echo "MARITACA_API_KEY=sua-chave-aqui" > .env
```

### Uso B√°sico com API

```python
import os
from maritaca_api import MaritacaAPI

# Inicializar cliente (usa MARITACA_API_KEY do ambiente)
client = MaritacaAPI()

# Gerar resposta para quest√£o ENEM
prompt = "Explique o conceito de Teoria da Resposta ao Item (TRI) no contexto do ENEM:"
response = client.generate_enem_response(prompt, max_tokens=300)
print(response)
```

### Uso B√°sico (Modo Local - Alternativo)

Se preferir usar o modelo local ao inv√©s da API:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# Carregar modelo base e adapter
base_model = "sabia-7b"  # Ajuste para o caminho do modelo base
adapter_path = "./checkpoint-367"

tokenizer = AutoTokenizer.from_pretrained(base_model)
model = AutoModelForCausalLM.from_pretrained(
    base_model,
    torch_dtype=torch.float16,
    device_map="auto"
)
model = PeftModel.from_pretrained(model, adapter_path)

# Gerar resposta
prompt = "Explique o conceito de Teoria da Resposta ao Item (TRI) no contexto do ENEM:"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=256,
        temperature=0.7,
        do_sample=True
    )

response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

Para mais exemplos, consulte:
- [`example_usage.py`](example_usage.py) - Exemplos de uso
- [`test_model_api.py`](test_model_api.py) - Testes com API
- [`maritaca_api.py`](maritaca_api.py) - Cliente da API

## üìä M√©tricas de Treinamento

### Resultados Finais
- **Loss Final**: 0.68
- **Token Accuracy**: 84.19%
- **Total de Steps**: 367
- **Epochs**: 1.0

### Evolu√ß√£o do Treinamento

| Step | Loss | Accuracy |
|------|------|----------|
| 25   | 1.12 | 75.13%   |
| 50   | 0.68 | 84.34%   |
| 100  | 0.65 | 84.41%   |
| 200  | 0.65 | 84.36%   |
| 300  | 0.64 | 84.63%   |
| 367  | 0.68 | 84.19%   |

üìà Para an√°lise detalhada, consulte [`ANALISE_TREINAMENTO.md`](ANALISE_TREINAMENTO.md).

## üîß Configura√ß√£o T√©cnica

### Hiperpar√¢metros LoRA
- **Rank (r)**: 32
- **Alpha (Œ±)**: 16
- **Dropout**: 0.05
- **Target Modules**: q_proj, k_proj, v_proj, o_proj
- **Bias**: none

### Stack Tecnol√≥gico
- **PEFT**: 0.18.0
- **TRL**: 0.25.1
- **Transformers**: 4.57.3
- **PyTorch**: 2.9.1
- **Datasets**: 4.4.1

## üìÅ Estrutura do Projeto

```
nlpenem/
‚îú‚îÄ‚îÄ README.md                 # Este arquivo
‚îú‚îÄ‚îÄ requirements.txt          # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ .gitignore               # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ example_usage.py         # Exemplos de uso do modelo
‚îú‚îÄ‚îÄ ANALISE_TREINAMENTO.md   # An√°lise detalhada do treinamento
‚îú‚îÄ‚îÄ adapter_config.json      # Configura√ß√£o do adapter LoRA
‚îú‚îÄ‚îÄ adapter_model.safetensors # Modelo adapter (LoRA weights)
‚îî‚îÄ‚îÄ checkpoint-*/            # Checkpoints do treinamento
    ‚îú‚îÄ‚îÄ checkpoint-100/
    ‚îú‚îÄ‚îÄ checkpoint-200/
    ‚îú‚îÄ‚îÄ checkpoint-300/
    ‚îî‚îÄ‚îÄ checkpoint-367/      # Checkpoint final
```

## üì¶ Checkpoints Dispon√≠veis

O projeto inclui 4 checkpoints salvos durante o treinamento:

- **checkpoint-100**: Step 100 (Loss: 0.65, Accuracy: 84.41%)
- **checkpoint-200**: Step 200 (Loss: 0.65, Accuracy: 84.36%)
- **checkpoint-300**: Step 300 (Loss: 0.64, Accuracy: 84.63%) ‚≠ê **Recomendado**
- **checkpoint-367**: Step 367 (Loss: 0.68, Accuracy: 84.19%) - Final

üí° **Recomenda√ß√£o**: O checkpoint-300 apresenta a melhor combina√ß√£o de m√©tricas (menor loss e maior accuracy).

## üéØ Casos de Uso

### 1. Resolu√ß√£o de Quest√µes ENEM
```python
questao = """
Quest√£o ENEM: Sobre a Teoria da Resposta ao Item (TRI), assinale a alternativa correta:
A) A TRI n√£o considera o n√≠vel de dificuldade dos itens
B) A TRI permite comparar provas de diferentes edi√ß√µes
...
"""
# Gerar resposta e explica√ß√£o
```

### 2. An√°lise de Desempenho
```python
notas = {
    "CH": 650.00,
    "CN": 620.00,
    "LC": 680.00,
    "MT": 700.00,
    "Reda√ß√£o": 900.00
}
# Analisar e fornecer orienta√ß√µes
```

### 3. Explica√ß√µes Did√°ticas
```python
# Explicar conceitos educacionais de forma did√°tica
prompt = "Explique a diferen√ßa entre nota TRI e nota bruta no ENEM:"
```

## ‚ö†Ô∏è Limita√ß√µes e Considera√ß√µes

- Este modelo foi fine-tuned para contexto educacional brasileiro e ENEM
- Os resultados devem ser validados por especialistas em educa√ß√£o
- N√£o substitui estudo tradicional e orienta√ß√£o pedag√≥gica profissional
- Pode conter vieses presentes no dataset de treinamento
- Requer modelo base SABIA-7B para funcionar

## üìù Licen√ßa

Este projeto est√° licenciado sob a [Apache License 2.0](https://opensource.org/licenses/Apache-2.0).

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìö Refer√™ncias e Cita√ß√µes

### TRL (Transformer Reinforcement Learning)
```bibtex
@misc{vonwerra2022trl,
    title        = {{TRL: Transformer Reinforcement Learning}},
    author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\'e}dec},
    year         = 2020,
    journal      = {GitHub repository},
    publisher    = {GitHub},
    howpublished = {\url{https://github.com/huggingface/trl}}
}
```

### LoRA (Low-Rank Adaptation)
```bibtex
@misc{hu2021lora,
    title={LoRA: Low-Rank Adaptation of Large Language Models},
    author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
    year={2021},
    eprint={2106.09685},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```

### SABIA-7B
- Modelo base: [SABIA-7B no Hugging Face](https://huggingface.co/sabia-7b)

## üë• Autores

- **XTRI** - Especialista em ENEM/TRI e an√°lise de dados educacionais
  - Professor de Ensino M√©dio
  - CEO da EdTech XTRI (Natal/RN)
  - Trabalha com dados educacionais cr√≠ticos (190k+ registros)

## üìß Contato

Para quest√µes, sugest√µes ou colabora√ß√µes:
- **GitHub**: [@xtribr](https://github.com/xtribr)
- **Reposit√≥rio**: [nlpenem](https://github.com/xtribr/nlpenem)

## üôè Agradecimentos

- Equipe do Hugging Face pelos frameworks TRL e PEFT
- Desenvolvedores do modelo SABIA-7B
- Comunidade open source de NLP em portugu√™s

---

‚≠ê Se este projeto foi √∫til para voc√™, considere dar uma estrela no reposit√≥rio!

**Nota**: Este modelo √© parte de um projeto educacional focado em an√°lise de dados ENEM e orienta√ß√£o estudantil. Desenvolvido com responsabilidade e compromisso com a educa√ß√£o de qualidade.
